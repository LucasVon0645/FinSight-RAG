dataset:
  path: "data/sentiment_analysis/financial_phrasebank/train"
  text_field: "sentence"
  label_field: "label"
  validation_split: 0.10
  test_split: 0.10
  seed: 42

model:
  pretrained_name: "distilbert-base-uncased"
  max_length: 256

training:
  output_dir: "models/sentiment_distilbert_phrasebank"
  overwrite_output_dir: true

  num_train_epochs: 3
  learning_rate: 2.0e-5
  weight_decay: 0.01

  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 4

  warmup_ratio: 0.06

  # progress + evaluation
  logging_steps: 25
  eval_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 2

  load_best_model_at_end: true
  metric_for_best_model: "f1_macro"
  greater_is_better: true

runtime:
  dataloader_num_workers: 0
  report_to: "none"   # set to "tensorboard" if you want TensorBoard

inference:
  model_dir: "C:/Users/User/projects/FinSight-RAG/models/sentiment_distilbert_phrasebank"  # where trainer saved the model
  device: "cpu"                 # cpu only
  batch_size: 16
  return_all_scores: true        # return scores for all labels
  top_k: null                    # or 1 for only top label
  id2label:
    0: negative
    1: neutral
    2: positive